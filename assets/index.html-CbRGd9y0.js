import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as i,f as n,o as r}from"./app-BvEWR9Cw.js";const p={};function l(o,e){return r(),a("div",null,[e[0]||(e[0]=i('<p>AI 实际上是两个独立的概念：</p><ul><li>ANI（弱人工智能），用 AI 做一件事，比如智能音箱或自动驾驶或网络搜索或在农业和工厂中的应用</li><li>AGN（强人工智能），它可以用来做任何事情，甚至可能超过人类</li></ul><h2 id="和传统编程对比" tabindex="-1"><a class="header-anchor" href="#和传统编程对比"><span>和传统编程对比</span></a></h2><p>如果想判断人脸，传统编程需要精心编写硬编码规则，才能识别人脸。而机器学习则从例子中学习，如果在机器学中编写一套规则是徒劳的，如果用机器学习，为每个图像都写下一个预期的答案，然后利用机器学习技术摸索一套规则，经过机器学习技术正确训练的规则，这比编写一套规则要好得多</p><p>机器学习包含两个重要阶段：</p><ul><li>训练阶段：输入数据训练出模型</li><li>推理阶段：用模型为新的数据输出答案</li></ul><p>基于训练数据和模型架构，在训练阶段中，机器可以习得数据与答案之间的转换规则，并将其封装在训练好的模型（trained model）中。这个过程将规则的蓝图作为输入，并且对其进行改变（或微调），让模型输出的结果越来越逼近预期结果。根据训练数据的多少、模型架构的复杂度和硬件的快慢，这一训练阶段会持续几毫秒到几天。这种机器学习方式，也就是用带标签的样例来逐步减小模型输出误差的方法，叫作<strong>监督式学习</strong>（supervised learning） 。绝大部分深度学习算法属于监督式学习。一旦有了训练好的模型，就可以将习得的规则应用到新数据上了（包括训练阶段没有出现的数据）。以上就是第二阶段，即推断阶段（inference phase），这一阶段相较训练阶段计算量较少，主要有两个原因：第一，推断阶段通常每次只针对一个输入（比如图像），而训练阶段则需要处理所有的训练数据；第二，在推断阶段，模型自身不会有任何变化</p><h2 id="通识" tabindex="-1"><a class="header-anchor" href="#通识"><span>通识</span></a></h2><h3 id="机器学习" tabindex="-1"><a class="header-anchor" href="#机器学习"><span>机器学习</span></a></h3><p>最常用的机器学习是学习如何从输入到输出的映射，这也被称为监督学习，比如输入一封电子邮件，并且输出表示是或不是垃圾邮件，这就是用于构建邮件筛选器的 AI 核心思想。输入一段音频，并且输出音频对应的文本，这就是语音识别。输入中文，并输出其它语言的翻译，这就是机器翻译。包括输入用户特征，向用户推荐感兴趣的广告，这就是推荐系统</p><p>监督学习的概念其实已经存在很多年了，但它最迅猛的发展还是在近几年，比如即使提供了很多数据，也不会导致想要的输出更精确，而 AI 真正的飞速发展得益于神经网络和深度学习的兴起。有了这些技术，才会导致提供的数据让 AI 性能更好</p><p>想要 AI 性能更强，更准确，需要以下几点：</p><ul><li>拥有大量数据，多多益善</li><li>训练一个非常大的神经网络</li></ul><h3 id="数据" tabindex="-1"><a class="header-anchor" href="#数据"><span>数据</span></a></h3><p>数据或者被称为数据集，比如有个想要给某个房子定价，可能会收集以下数据：</p><table><thead><tr><th>大小（平米）</th><th>卧室数量</th><th>价格（1000 人民币）</th></tr></thead><tbody><tr><td>90</td><td>2</td><td>612</td></tr><tr><td>110</td><td>3</td><td>752</td></tr><tr><td>129</td><td>3</td><td>876</td></tr><tr><td>200</td><td>4</td><td>153</td></tr></tbody></table><p>如果想构建一个 AI 系统帮助设置房子的价格，可能把输入设为房子的大小，输出设为房子的价格，然后让 AI 去学习。但有可能不仅仅根据房子大小来定价，而想要根据卧室数量来定价，这时，输入就是房子大小和卧室数量。所以给定一个数据集，这个时候取决于自身的需求来决定什么是输入和输出</p><p>因此数据集非常重要，获取数据的方法：</p><ul><li>手动标记</li><li>观察行为</li></ul><p>多亏互联网，有很多的数据集可以下载，同时也不要认为，有数据就一定能创造价值，所以不要认为无脑为了获取数据而过度投入。数据本身也是混乱的，如果质量比较差，则会让 AI 学习出不准确的结果，因此如何清理数据也是很重要的</p><h3 id="深度学习" tabindex="-1"><a class="header-anchor" href="#深度学习"><span>深度学习</span></a></h3><p>深度学习和神经网络两个词汇可以交替使用，它们都是机器学习的工具，神经网络实际上那就是帮助输入计算出输出，神经元是神经网络中最小单位。比如你想卖一件衣服，价格，邮费，营销，材质都是可能影响用户购买的因素，而价格和运输成本需要一个神经元计算出用户的购买力，营销需要一个神经元计算出用户的认知程度，营销和材质需要一个神经元计算出用户对衣服的质量判断，这些前置神经元就可以计算出用户的价格负担，认知程度，以及质量的判断，最后将这三者作为一个输入交给一个神经元并输出预估结果，这就是整个神经网络的工作流程</p><p>只要给神经网络输入和输出，它就会自动搞清楚中间的事情，因此只需要给大量的数据，从而让神经网络自动学习从输入到输出的映射</p><p>比如使用神经网络识别人脸时，神经网络的输入是每个像素的值，但神经网络的魔法在于，并不需要知道神经网络计算的过程，它会自动计算出来，只需要给它大量的数据就行</p><h3 id="损失函数-loss-function-成本函数-cost-function-目标函数-objective-function" tabindex="-1"><a class="header-anchor" href="#损失函数-loss-function-成本函数-cost-function-目标函数-objective-function"><span>损失函数 (Loss Function) / 成本函数 (Cost Function) / 目标函数 (Objective Function)</span></a></h3><p>损失函数是一个数学函数，用于衡量模型预测输出与真实目标值之间的差异或错误程度。它量化了模型在给定数据集上的表现有多“差”。训练一个机器学习模型本质上是一个优化问题：我们希望找到一组模型参数，使得模型在训练数据上的表现最好。为了衡量“最好”，我们需要一个客观的数值指标来量化模型的错误。损失函数提供了这个指标。模型的训练目标就是最小化这个损失函数的值。</p><p>损失函数接收模型的预测输出（例如，神经网络最后一层的输出）和对应的真实标签或目标值作为输入，然后输出一个单一的非负数值。数值越大，表示模型的预测越不准确，错误越大；数值越小，表示模型的预测越接近真实值。 不同的任务类型使用不同的损失函数：</p><ul><li>对于回归任务，常用的损失函数包括均方误差（Mean Squared Error, MSE）和平均绝对误差（Mean Absolute Error, MAE）。</li><li>对于分类任务，常用的损失函数包括交叉熵损失（Cross-Entropy Loss）和二元交叉熵损失（Binary Cross-Entropy Loss）。</li><li>对于多标签分类任务，常用的损失函数包括二元交叉熵损失（Binary Cross-Entropy Loss）和稀疏分类交叉熵损失（Sparse Categorical Cross-Entropy Loss）。</li><li>对于序列预测任务，常用的损失函数包括序列交叉熵损失（Sequence Cross-Entropy Loss）和序列均方误差（Sequence Mean Squared Error, SMSE）。</li></ul><h3 id="梯度下降-gradient-descent" tabindex="-1"><a class="header-anchor" href="#梯度下降-gradient-descent"><span>梯度下降 (Gradient Descent)</span></a></h3><p>梯度下降是一种迭代优化算法，用于寻找函数（在这里特指损失函数）的局部最小值。它的核心思想是沿着函数梯度（导数）的负方向移动参数，因为梯度指向函数值增长最快的方向，而其负方向则指向函数值下降最快的方向。</p><p>训练模型的目的是最小化损失函数。梯度下降提供了一种系统性的方法来调整模型的参数（如权重和偏置），使得每一次调整都能使损失函数的值有所下降，从而逐步接近损失函数的最小值。这是大多数现代机器学习模型（包括神经网络）学习参数的主要算法。</p><p>梯度下降的变体 (How - Variations):</p><ul><li>批量梯度下降 (Batch Gradient Descent): 使用整个训练集来计算梯度并更新一次参数。计算准确但计算量大，对于大型数据集效率低。</li><li>随机梯度下降 (Stochastic Gradient Descent, SGD): 每次只使用一个训练样本来计算梯度并更新参数。计算速度快，但梯度波动大，可能导致训练过程不稳定。</li><li>小批量梯度下降 (Mini-batch Gradient Descent): 每次使用一小部分（一个批次）训练样本来计算梯度并更新参数。这是实际应用中最常用的方法，兼顾了计算效率和训练稳定性。它提供了梯度的近似，比 SGD 稳定，比批量梯度下降计算量小。</li></ul><h3 id="优化器-optimizer" tabindex="-1"><a class="header-anchor" href="#优化器-optimizer"><span>优化器 (Optimizer)</span></a></h3><p>优化器是实现优化算法（通常是梯度下降或其变种）的具体方法。它根据损失函数计算出的梯度，决定如何调整和更新模型的参数。</p><p>尽管梯度下降提供了参数更新的基本方向（梯度的负方向），但简单地按照固定的学习率更新参数可能效率低下，容易陷入局部最小值，或者在平坦区域进展缓慢，在陡峭区域波动过大。优化器提供了更智能、更复杂的参数更新策略，旨在加速训练过程、提高收敛稳定性、帮助跳出局部最优等。</p><p>优化器接收模型的参数和计算出的梯度作为输入。它根据自身实现的算法（如 SGD、Adam、RMSprop 等）来计算参数的具体更新量，然后应用这个更新量到模型参数上。 常见的优化器及其大致工作方式：</p><ul><li>随机梯度下降 (SGD): 基于 SGD 的优化器使用学习率来控制参数更新的步长。它简单易用，但在复杂的损失函数上可能收敛较慢。</li><li>Adam (Adaptive Moment Estimation): Adam 是一种自适应学习率优化器，它结合了动量和 RMSprop 的优点。它使用过去梯度的指数衰减平均来调整每个参数的学习率，从而在训练过程中动态调整学习率。</li><li>RMSprop: RMSprop 是一种自适应学习率优化器，它使用过去梯度的平方的指数衰减平均来调整每个参数的学习率。它在处理非平稳目标时表现良好。</li><li>Adagrad: Adagrad 是一种自适应学习率优化器，它根据每个参数的历史梯度平方和来调整学习率。它在训练初期表现良好，但随着训练进行，学习率会迅速减小，可能导致训练停滞。</li><li>Adadelta: Adadelta 是 Adagrad 的改进版本，它使用过去梯度的平方的指数衰减平均来调整学习率，从而避免了 Adagrad 学习率迅速减小的问题。</li></ul><h3 id="过拟合和欠拟合" tabindex="-1"><a class="header-anchor" href="#过拟合和欠拟合"><span>过拟合和欠拟合</span></a></h3><p>过拟合是指机器学习模型在训练集上表现得非常好，几乎完美地记住了训练数据中的每一个样本，包括其中的噪声和异常值。然而，当将这个模型应用于新的、未见过的数据（如验证集或测试集）时，其性能会急剧下降，远不如在训练集上的表现。简单来说，模型学到了训练数据的“细节”和“噪声”，而不是泛化到数据的潜在“规律”。</p><p>与过拟合相对的是欠拟合 (Underfitting)，指模型过于简单，甚至无法在训练数据上学到足够的信息，导致在训练集和测试集上的表现都很差。</p><p>机器学习模型的最终目标是<strong>泛化</strong>，即能够对新的未知数据做出准确的预测或判断。过拟合的模型失去了泛化能力，它仅仅是“记住”了训练数据，而不是“理解”了数据背后的模式。因此，一个过拟合的模型在实际应用中是不可靠的，会做出错误的预测。</p><p>过拟合通常在以下情况下发生：</p><ul><li>模型复杂度过高 (Model Complexity): 模型拥有过多的参数或层，导致它有足够的能力去“记忆”训练数据中的每一个点，而不仅仅是捕捉主要趋势。</li><li>训练数据量不足 (Insufficient Data): 相对于模型的复杂度，训练数据量太少。模型没有看到足够多的样本来理解真正的底层分布，只能死记硬背现有样本</li><li>训练时间过长 (Training for Too Long): 在训练过程中，如果模型在训练集上迭代次数过多，它可能会开始学习噪声而不是信号。</li><li>训练数据包含噪声 (Noisy Data): 训练数据中存在错误标记或无关的噪声，模型也会试图去拟合这些噪声。</li></ul><p>检测过拟合最常用的方法是：</p><ul><li>监控训练集和验证集/测试集的性能: 在训练过程中，同时评估模型在训练集和独立的验证集（或测试集）上的性能指标（如准确率、损失）。 如果模型在训练集上的性能持续提升（损失持续下降），而在验证集上的性能达到一个峰值后开始下降（损失开始上升），这就是过拟合的典型迹象。训练性能和验证性能之间出现显著差距。 经典的表现是绘制训练损失和验证损失随训练 epoch 变化的曲线图。过拟合发生时，两条曲线会开始“分叉”。</li></ul><p>有多种技术可以减轻或防止过拟合：</p><ul><li>增加训练数据量 (More Data): 这是最直接有效的方法。更多的数据可以帮助模型学到更真实的模式，而不是噪声。</li><li>简化模型 (Simplify Model): 使用更简单的模型结构，减少参数数量。例如，减少神经网络的层数或每层的神经元数量。</li><li>正则化 (Regularization): 在损失函数中添加一个惩罚项，以限制模型的复杂度。常见的正则化方法包括 L1 正则化（Lasso）和 L2 正则化（Ridge）。</li><li>提前停止 (Early Stopping): 在训练过程中监控验证集的性能，当验证集性能不再提升时，提前停止训练。</li><li>数据增强 (Data Augmentation): 通过对训练数据进行随机变换（如旋转、缩放、翻转等）来增加训练样本的多样性，从而提高模型的泛化能力。</li><li>Dropout: 在训练过程中随机丢弃一部分神经元，以减少模型对特定神经元的依赖，从而提高泛化能力。</li><li>交叉验证 (Cross-Validation): 例如 k 折交叉验证，将训练数据分成 k 份，轮流将一份作为验证集，其余 k-1 份作为训练集进行训练和评估。这能更可靠地评估模型的泛化能力，并帮助选择合适的超参数。</li><li>特征选择/降维 (Feature Selection/Dimensionality Reduction): 移除与任务无关或冗余的特征，降低数据维度，减少模型需要学习的复杂性。</li></ul><h2 id="其他机器学习技术" tabindex="-1"><a class="header-anchor" href="#其他机器学习技术"><span>其他机器学习技术</span></a></h2><p>神经网络不是唯一选择，还有一些非神经网络机器学习技术</p><p>朴素贝叶斯分类器（naive Bayes classifier）是最早的机器学习方法之一。简单地说，对于计算事件发生概率的贝叶斯定理，其实现过程基于两个前提：第一，对已有事件发生可能性的先验认知；第二，观测到的数据，即特征（feature）。这一方法可以用观测到的数据计算每个事件类别对应的概率，然后按照最高的概率（事件发生可能性），将观测到的数据划入一个已知的类别。该方法假设观测到的数据之间是相互独立的，这是一个非常强的假设，同时对现实中的现象有所简化，名字中的“朴素”正是由此而来。逻辑回归（logistic regression）也是一种分类方法。由于其简单和灵活多变的特性，它至今都非常流行，通常是数据科学家处理分类任务的首选方法</p><p>核方法（kernel method）主要用于解决二分类问题，即共有两种类别的问题。它将原数据映射到新的更高维空间，并寻找一种转换方式，实现两种类别示例之间距离（又称margin，即间隔）的最大化，从而进行分类。支持向量机（SVM）是核方法最有代表性的例子</p><p>决策树（decision tree）的结构与流程图类似。可以对输入的数据进行分类，或者根据输入的数值预测输出。在流程图的每一步，只需要简单地回答一个答案为“是”或“否”的问题，比如“X特征的值是否大于特定阈值”。每一步的流程取决于所选答案，然后进入答案对应的路径，在那里会出现另一个“是”或“否”的问题，以此类推。一旦到达了流程图的终点，也就获得了最终的答案。如你所见，对所有人而言，决策树非常直观且容易理解</p><p>随机森林（random forest）和梯度提升机（gradient-boostedmachine）通过整合大量有特定功能的决策树来提高整体的准确率。集成化（ensembling）又名集成学习（ensemble learning），这种方法会训练一些机器学习模型的集合（集成），并在推断阶段将它们的整体输出作为推断结果。现在，梯度提升是用来处理非感知数据最好的算法之一，例如信用卡诈骗检测中的信用数据。和深度学习一样，它也是Kaggle这类数据科学竞赛中较为常用的技巧</p><h2 id="流程" tabindex="-1"><a class="header-anchor" href="#流程"><span>流程</span></a></h2><p>机器学习的流程：收集数据-&gt;训练模型-&gt;派送模型</p><p>数据科学的流程：收集数据-&gt;分析数据-&gt;提出假设-&gt;开展行动</p><h2 id="机器学习框架" tabindex="-1"><a class="header-anchor" href="#机器学习框架"><span>机器学习框架</span></a></h2><p>许多团队都开发了机器学习框架用于更好的进行机器学习：</p><ul><li>TensorFlow</li><li>PyTorch</li></ul><h2 id="电脑需求" tabindex="-1"><a class="header-anchor" href="#电脑需求"><span>电脑需求</span></a></h2><p>GPU 原本是为了处理图形而设计的硬件，但其实非常适合用来构建大型神经网络，由于需要更强的算力，GPU 已经被证明是非常匹配这种需求的硬件</p><h2 id="术语" tabindex="-1"><a class="header-anchor" href="#术语"><span>术语</span></a></h2><ul><li>机器学习：这是一个研究领域，它赋予计算机无需明确编程就能学习的能力</li><li>数据科学：从数据中提取知识和见解的科学</li><li>深度学习：使用神经网络来进行输出到输入的映射</li></ul><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://zh.d2l.ai/" target="_blank" rel="noopener noreferrer">动手学习深度学习</a></li></ul>',66)),n(" todo ")])}const c=t(p,[["render",l]]),h=JSON.parse(`{"path":"/ai/","title":"AI","lang":"zh-CN","frontmatter":{"title":"AI","category":"AI","tag":["AI"],"article":false,"description":"AI 实际上是两个独立的概念： ANI（弱人工智能），用 AI 做一件事，比如智能音箱或自动驾驶或网络搜索或在农业和工厂中的应用 AGN（强人工智能），它可以用来做任何事情，甚至可能超过人类 和传统编程对比 如果想判断人脸，传统编程需要精心编写硬编码规则，才能识别人脸。而机器学习则从例子中学习，如果在机器学中编写一套规则是徒劳的，如果用机器学习，为每个...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"AI\\",\\"description\\":\\"AI 实际上是两个独立的概念： ANI（弱人工智能），用 AI 做一件事，比如智能音箱或自动驾驶或网络搜索或在农业和工厂中的应用 AGN（强人工智能），它可以用来做任何事情，甚至可能超过人类 和传统编程对比 如果想判断人脸，传统编程需要精心编写硬编码规则，才能识别人脸。而机器学习则从例子中学习，如果在机器学中编写一套规则是徒劳的，如果用机器学习，为每个...\\"}"],["meta",{"property":"og:url","content":"https://jinqiu.wang/ai/"}],["meta",{"property":"og:site_name","content":"JQiue's notes"}],["meta",{"property":"og:title","content":"AI"}],["meta",{"property":"og:description","content":"AI 实际上是两个独立的概念： ANI（弱人工智能），用 AI 做一件事，比如智能音箱或自动驾驶或网络搜索或在农业和工厂中的应用 AGN（强人工智能），它可以用来做任何事情，甚至可能超过人类 和传统编程对比 如果想判断人脸，传统编程需要精心编写硬编码规则，才能识别人脸。而机器学习则从例子中学习，如果在机器学中编写一套规则是徒劳的，如果用机器学习，为每个..."}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-19T06:51:15.000Z"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:modified_time","content":"2025-06-19T06:51:15.000Z"}]]},"git":{"createdTime":1750315875000,"updatedTime":1750315875000,"contributors":[{"name":"JQiue","username":"JQiue","email":"861947542@qq.com","commits":1,"url":"https://github.com/JQiue"}]},"readingTime":{"minutes":16.37,"words":4910},"filePathRelative":"ai/README.md","excerpt":"<p>AI 实际上是两个独立的概念：</p>\\n<ul>\\n<li>ANI（弱人工智能），用 AI 做一件事，比如智能音箱或自动驾驶或网络搜索或在农业和工厂中的应用</li>\\n<li>AGN（强人工智能），它可以用来做任何事情，甚至可能超过人类</li>\\n</ul>\\n<h2>和传统编程对比</h2>\\n<p>如果想判断人脸，传统编程需要精心编写硬编码规则，才能识别人脸。而机器学习则从例子中学习，如果在机器学中编写一套规则是徒劳的，如果用机器学习，为每个图像都写下一个预期的答案，然后利用机器学习技术摸索一套规则，经过机器学习技术正确训练的规则，这比编写一套规则要好得多</p>\\n<p>机器学习包含两个重要阶段：</p>","autoDesc":true}`);export{c as comp,h as data};
