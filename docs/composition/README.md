---
title: 计算机组成原理
category: 计算机原理
article: false
---

::: info 前置知识

+ 数字电路
:::

从肉眼来看，计算机是由 CPU、内存，显示器等这些设备组成的硬件，虽然绝大部分人都是从事应用层面的软件开发，但是组成原理是计算机其他课程的一个引导，因为向下可以学习数电，向上可以学习编译原理和操作系统这些课程，所以说无论学习计算机的哪一门核心课程都应该先学习一下计算机组成原理，这样会对硬件原理和软件架构都有一个全局性的了解

但是这门课也是非常难的一门，因为概念非常多，并且信息量很大，比如想要理解 CPU 中的算数逻辑单元怎么实现加法，就需要涉及到如何将整数表示成二进制，如果讨论计算机的指令如何从高级语言变成可执行的机器码，那么就会变成编译原理这门核心课

那么总结来说，计算机组成研究的是计算机中的部件之间的连接关系和相互关系，以及它们之间的工作原理

::: center
![organization-1](../images/organization-basic-1.png)
:::

到底是学什么呢？其实有点像装电脑

## 电脑的硬件组成

电脑必须要有三大件，CPU、内存和主板

CPU 是电脑中最核心的硬件，它的全名叫做中央处理器（Central Processing Unit），所有的计算都是交给 CPU 进行的，同时 CPU 几乎是整个电脑中造价最贵，科技水平最高的

第二个是内存（Memory），打开的程序，都要加载到内存中去才能运行，内存越大，放的东西越多，而 CPU 就是通常处理内存中数据，但是 CPU 不能直接插到内存上

主板提供了 CPU 和内存连接的通道，主板是一个有各种各样插槽的配件，CPU 和内存都需要插到主板上，主板的芯片组和总线解决了 CPU 和内存之间如何通信的问题，芯片组控制了数据传输的流转，总线是数据传输的通道

当有了这三大件，只要配上电源供电，计算机就可以运行起来了，但是还缺少一些输入输出设备，也就是 I/O 设备，比如没有显示器就看不到计算机输出的图像、文字等信息，这就是所谓的输出设备。鼠标键盘也不能少，这样才能向计算机中输入数据，它们也就是所谓的输入设备

最后可能需要一个硬盘，这样数据才能够永久的保存下来，且大部分人都会使用机箱，装上风扇，解决灰尘和散热问题，不过它们都不是计算机的必备硬件，也就是说拿鞋盒当机箱都没有问题

如果想要打游戏，可能还需要配上显卡，显卡也是必不可少的，可能有的主板自带显卡或者 CPU 自带显卡，但是如果要玩游戏，或者做深度学习，多半就要买一张独立的显卡插在主板上，显卡也里有一个处理器，也就是 GPU，它也可以做运算

## 冯诺依曼体系结构

一台电脑就这么组装起来了，但是平常使用的智能机也是这样的吗？

手机由于体积原因，并没有什么所谓的 CPU 插槽和内存插槽这些东西，所以手机制造商将这些东西都封装到一个芯片里，然后嵌入手机的主板上，这种方式叫做 SoC（System on a Chip）。这样看来电脑和手机可能组成方式不太一样，但是程序的运行方式没什么区别，都是将程序加载到内存中执行。这是因为个人电脑，手机等设备都遵循着一个概念，即**冯诺依曼体系结构**，也叫存储程序计算机。它有两种概念，一个是**可编程**，一个是**存储**

::: tip 冯诺依曼体系结构
将程序指令和数据一起存储的计算机设计概念结构
:::

计算机是由各种门电路组成的，通过组装成一个电路板，来完成特定的程序，一旦需要修改程序，就必须重新组装电路，这样的计算就就是不可编程的，因为程序在硬件层面上被写死了。比如计算器只能做加减乘除，做不了任何计算逻辑固定之外的事。如果将程序本身存储在内存中，然后通过加载不同的程序来解决不同的问题，那么就实现了可编程

早期计算机只能运行固定用途的程序，改变程序必须更改结构，重新设计电路，在当时重启程序并不像现在重新编译一样简单，这就导致计算机非常局限，于是冯诺依曼提出了将程序存储起来，并设计通用的电路，运行程序的时候，把程序当成电路能够理解的语言，然后让通用电路执行相关的逻辑，这就是冯诺依曼体系的核心概念：**存储程序指令，并设计通用电路**

::: tip 现代计算机结构
现代计算机结构从本质上来讲还是冯诺依曼结构，但对原有的结构进行了改变来解决冯诺依曼原有结构 CPU 和存储设备之间的性能差异，在这个结构中，存储器，运算器，控制器在一个结构上面，现在计算机的结构可以理解为**以存储器为核心的结构**
:::

ENIAC 是 1946 年在美国宾夕法尼亚大学制成的，但实际上真正意义上的第一台计算机是阿塔纳索夫-贝瑞计算机，ENIAC 发明者是从阿塔纳索夫继承了电子数字计算机的主要设计构想，因此阿塔纳索夫-贝瑞计算机是世界上第一台计算机，而 ENIAC 是通用的第一台电子数字计算机，因为 ENIAC 是可编程的计算机

::: center
![organization-basic-2](../images/organization-basic-2.jpg)
:::

## 计算机的分类

+ 电子模拟计算机：通过电压来表示数据，并用盘上连线控制，它的精度较低，存储量较小，没有逻辑判断能力，而数字计算机通过数字 0 和 1 表示，并通过程序来控制，它的精度非常高，存储量非常大，逻辑判断能力也非常强

+ 电子数字计算机：是现在最主流的计算机，通常也被称为电脑或者电子计算机，且可以进一步分为专用计算机和通用计算机，**它们是根据计算机的效率、速度、价格、运行的经济性和适应性来划分的**

专业计算机是最有效，最经济和最快速的计算机，但是他的适应性很差。通用计算机适应性很强，但是牺牲了效率，速度和经济型，通用计算机又可以分为超级计算机，大型机，服务器，PC 机，单片机和多核机，区别在于体积，简易性，功耗，性能，数据存储容量，指令系统规模和机器价格

::: center
![organization-basic-3](../images/organization-basic-3.png)
:::

+ 个人计算机：通常对个人用户来讲提供良好的性能，且价格低廉

+ 服务器：为多用户运行大型程序的计算机，执行大负载任务，通常是多个用户并行访问，提供比个人计算机更强的性能以及更加可靠的稳定性。低端服务器一般用于商务应用或者 Web 服务，而高端服务器又叫做**超级计算机**，常用于科学计算，这类计算机代表着最高价格以及最高的计算性能，但在整个计算机市场中占用的比例较少，跟个人计算机比起来，当前民用最强 CPU 连超算的十分之一都赶不上，可谓差距之大

+ 嵌入式计算机：是数量最多的一类，常用于汽车，电视、控制飞机等设备的处理器，它的设计目标是运行单一的应用程序，对成本和功耗有严格限制，必须快速的执行有限功能，且必须保证正常运转

## 程序概念

计算机系统由硬件和系统软件组成的，它们共同来运行应用程序

计算机的硬件只能执行简单的低级指令，一个复杂的应用程序到简单的指令需要经过多个软件层次来将高层次的操作翻译成简单的低级指令，这是一种抽象的解释。在层次中，最外层是应用软件，中间是硬件，而系统软件在两者之间

### 系统软件

系统软件提供操作系统、编译程序、加载程序、汇编程序等，对于现代计算机系统来说，**操作系统**和**编译程序**是必须的。操作系统是用户程序和硬件之间的接口，提供了基本的输入和输出，分配内外存，为应用程序提供计算机资源的操作

编译程序用于将高级语言编写的程序翻译成硬件能够执行的指令，对于计算机来说最简单的信号是“通”和”断“，所以计算机用两个符号 0 和 1 表示。也因此计算机的语言通常被称之为**二进制数**，每个符号就是一个**二进制位**或**一位**（bit），而计算机指令就是一个个二进制位组成的位串

### 转向高级语言

最初程序员是通过二进制来和计算机打交道的，由于二进制太过难以理解，它们很快发明了助记符，最初助记符是手工翻译成二进制，后来开发了一种**汇编程序**，将助记符自动翻译成对应的二进制，这种符号语言又叫**汇编语言**，而计算机理解的二进制语言叫**机器语言**

后来人们意识到可以编写一个能够将接近人类语言翻译成计算机指令的程序，于是就设计了高级语言的编译程序，使用高级编程语言大大提高了软件的开发效率，这些高级语言由一些单词和代数符号组成，可以由编译器转换成汇编语言，再由汇编器转换成机器语言交给计算机执行

## 计算机的性能

对于计算机来说，如何评价它的性能是很重要的，但是现代计算机采用了大量先进的性能改进方法，使性能评价极为困难

如果在两台计算机中运行同一个程序，可以认为首先完成的那台计算机更快，如果是服务器，则应该是完成量最多的那台计算机更快。个人计算机强调响应时间，服务器则强调吞吐率。因此对于不同的计算机来说，应该采用不同的性能度量标准

::: tip 响应时间和吞吐率

+ 响应时间：指计算机完成某个任务的总时间
+ 吞吐率：指单位时间内完成的任务数量
:::

想要增加计算机的性能，就要减少响应时间，增加吞吐率，但是通常减少响应时间也提升了吞吐率

一般将性能定义为响应时间的倒数：

::: center
性能 = 1 / 响应时间
:::

响应时间越短，性能数值越大，如果一个程序在处理器 A 上需要 6s 完成，而在处理器 B 上需要 3s 完成，根据公式算出，A 的性能是 1/6，而 B 的性能是 1/3，A 和 B 的性能比为 2，说明 B 的性能是 A 的两倍

### 频率

CPU 频率指 CPU 内部时钟的频率，单位为赫兹(Hz)，时钟频率决定 CPU 一个时钟周期内可以执行的指令数，频率越高，CPU 在同样时间内可以执行的指令就越多，理论上处理能力越强。但频率过高也会增加功耗。目前常见CPU 主频在 2GHz 至 5GHz 之间

CPU时钟简单来说就是用于同步和调控 CPU 内部各个组件工作的信号发生器

具体来说:

CPU 时钟通过晶体振荡器产生固定频率的时钟脉冲信号，

时钟频率决定了CPU每秒能执行的时钟周期数。更高频率意味着更高计算能力。

每一个时钟周期内CPU可以执行一个狭义指令。多核 CPU 各核共用一个时钟。

时钟信号通过时钟总线传输到CPU内部各模块,使指令寄存器、ALU等均衡工作。

时钟信号起到同步和协调各模块间工作的作用,是CPU正常运行的基础。

时钟也与CPU外部总线、存储器同步,协调CPU和外围设备工作。

所以总体来说,CPU时钟就像CPU内部的“心跳”指挥棒,它规律有序的时钟信号负责驱动和协调CPU各部件的计算活动。时钟频率也决定了CPU的基本计算能力。

CPU时钟频率主要由以下几个因素决定:

制程技术
时钟频率直接取决于CPU的制程大小。现代CPU以每年约18个月的速度迈向更小的制程技术。

超频能力
频率还取决于CPU的设计,更高频率需要极致优化时钟信号传输和电路稳定性。

生产工艺
同一制程下,不同IDM厂商靠工艺优势可提高时钟频率。

供电电压
时钟频率随供电电压线性增加,但过高电压会使寿命下降。

核心数目
多核时系统频率往往低于同期单核,考虑整体功效需求。

散热设计
时钟频率受温度影响,好的散热保证可稳定高频运行。

微架构优化
优秀微架构比制程小可带来更高时钟频率。

功耗限制
TDP功耗上限影响高负载时所能设置的时钟频率。

PCB布局
PCB布局好坏关系到时钟信号质量和稳定性。

所以总体来说,频率由多方面因素共同决定,是CPU综合竞争力的重要指标之一

Hz(赫兹):时钟频率的基本单位,代表每秒钟脉冲个数。

kHz(千赫):通常用来表示计算机初期CPU较低的频率。1kHz=1000Hz。

MHz(兆赫):1980-1990年代中低端CPU和周边设备的主流频率单位。1MHz=1000kHz。

GHz(吉赫):1990年代晚期高性能CPU进入GHZ时代,到21世纪已普及。1GHz=1000MHz。

THz(太赫):未来可能的极高频率。现仅用于一些新兴设备,如量子计算机。1THz=1000GHz。

1Hz只能表示CPU时钟的频率,即每秒钟产生的时钟脉冲数,但不能确定一条指令的执行时间

正确来说:

CPU时钟频率(Hz)决定了每秒能产生的最大时钟脉冲数。

每一个时钟脉冲周期内,CPU只能执行非常简单的操作,如读取/解码一条指令。

不同类型的指令执行时间不同,一般需要多个时钟周期完成。比如乘法可能需要几十个周期。

现代CPU采用流水线和超标量等技术,能同时执行多条指令。

IPC(每周期指令执行数量)决定了实际每秒能完成的指令数量。

IPC与CPU架构、流水线套深度等因素有关,同等频率下IPC不同的CPU性能也不同。

所以总结:

1Hz时钟频率仅表示每秒最大时钟脉冲数。

单条指令通常需要多个时钟周期完成,取决于指令类型和CPU架构。

CPU每秒实际完成的指令取决于IPC指标。

仅看时钟频率无法精确评判CPU单次指令执行能力。需要结合IPC等指标进行评估。

IPC(Instructions Per Clock)指每时钟周期执行多少条指令。

它是衡量CPU指令级并行能力的一个重要的参数:

IPC取决于CPU内部的流水线结构和预取机制。架构愈优秀,IPC愈高。

同频率下,IPC较高的CPU单位时间内能执行的指令就更多,性能相对较强。

现代高速CPU通过深度流水线化和超标量技术,每时钟周期可以执行1-3条以上指令。

测试IPC的方法是记录运行程序时用了多少时钟周期完成多少条指令。

一些常见CPU的IPC大约为:

Pentium Pro/PII约1条
Core i3/i5约2条
Ryzen/Core i7约2-3条
最新型号可能达3-4条
所以简单来说:

IPC反映了CPU一次能执行多少条指令,较高IPC代表指令级并行能力强。

它是衡量同样时钟下实际指令执行能力的重要参考指标。

理解IPC对评价CPU性能影响很重要。结合时钟频率,IPC更真实反应计算能力。

时间虽然能够衡量性能，但有两个问题：

+ 时间不准：一个程序不一定每次运行时间是一样的，因为 CPU 实际上在各个程序之间切换
+ CPU 性能：CPU 可能满载运行，也可能降频运行，导致时间有所差异

所以应该对 CPU 时间进行拆解，将执行时间变成时钟周期数和时钟周期时间的乘积：

::: center
程序的 CPU 执行时间 = CPU 时钟周期数 * CPU 时钟周期时间
:::

时钟周期时间就是 CPU 主频，比如 AMD 3200G 的主频是 3.6GHz，可以简单粗暴的理解为，CPU 在 1 秒内执行的指令是 3.6G 条，CPU 内部是由晶振驱动的，类似于墙上的挂钟，“滴答滴答”一秒一秒的走，通过挂钟就能识别出来最小的单位是秒。而 CPU 每一次的震荡时间就是时钟周期时间，只要这个主频越高就代表它走的越快，因此最简单的性能提升方式就是缩短时钟周期时间，但是对于人类说这个操作相当于更换了 CPU，因此将目光瞄向了时钟周期数，如果能减少程序需要的时钟周期数，一样能够提升性能

时钟周期数受程序的指令数影响较大，所以可以进一步拆解成“指令数 * 每条指令的平均时钟周期数”，简称 CPI，这样上面的公式就变成了：

::: center
程序的 CPU 执行时间 = 指令数 \* CPI \* CPU 时钟周期时间
:::

除了优化这些东西来提升性能，还可以将一个芯片集成多个 CPU 来提升性能，所以就出现了向单核处理器向多核处理器的转变

## 功耗墙

只要在 CPU 多放一些晶体管，提高时钟频率就能够让它更快，但是对于 CPU 来说是有功耗上限的，因为同一个体积的性能提升是有限的，仅通过堆硬件的方式，在如今已经不能够满足对程序性能的需求了，所以需要从以下几个方面入手：

+ 加速大概率事件
+ 通过流水线提高性能
+ 通过预测提高性能

## 计算机的计算单位

### 容量单位

| bit    | Byte  | KB     | MB       | GB        | TB     | PB     | EB       |
| ------ | ----- | ------ | -------- | --------- | ------ | ------ | -------- |
| 比特位 | 字节  | 千字节 | 兆字节   | 吉字节    | 太字节 | 拍字节 | 艾字节   |
| -      | 8bits | 1024B  | 1024KB   | 1024MB    | 1024GB | 1024TB | 1024EB   |
| 门电路 | -     | 寄存器 | 高速缓存 | 内存/硬盘 | 硬盘   | 云硬盘 | 数据仓库 |

::: warning
在千字节之后，所有的单位的换算关系都是 1024，只有字节和比特位使用的是 8 进制位，同时 1024 = 2^10^
:::

::: caution 为什么网上买的硬盘容量标称 500G，格式化之后变成了 465G？
这是因为硬盘制造商使用的是 10 进制位来标记容量，也就是说 1G 等于1000MB，而不是 1024MB，所以(500 * 1000^3^)/1024^3^ 约等于 465G，硬盘商使用 1000 进制位，则是因为硬盘的扇区，也就是存储数据的地方，在记住这个扇区的容量时，使用的是人类容易理解的十进制，更容易去沟通和协商
:::

### 速度单位

+ 网络速度

在互联网走进千家万户的同时，会经常听到各种 2M、4M、以及 10M 这样的关键字，这里的单位并不是存储单位，而是一种速度单位。

::: caution 为什么电信拉的 100M 光纤，测试峰值速度只有 12M 每秒？
在网络中常用速度单位为：Mbps，100M 是 100Mbps 的缩写，而 100Mbps 等于 100Mbit/s，所以换算成实际的速度单位为：100Mbit/s = (100/8)MB/s = 12.5MB/s
:::

## 字符与编码集

字符也就是在计算机表达的"语言"，常见的包括:数值、字母、文字和符号,如:1、a、A、试、$...都表示的是一个字符，在计算机中，不同的字符可能需要不用的存储容量进行存储

字符集则表示多个字符的集合，每个字符集可以包括不同的字符

将字符集中的字符编码(映射)成集合中的某一个对象如：比特模式、自然数序列、电脉冲等,以方便字符在计算机中存储和在计算机网络中传递

字符集表示:多个字符的集合,字符编码则是:将字符集中的字符映射为特定的字节或者字节序列,它表示的是一种规则。通常特定的字符集采用特定的编码方式（即一种字符集对应一种字符编码,如: ASCII、ISO-8859-1、GB2312、GBK 都是表示了字符集又表示了对应的字符编码,但Unicode字符集是特例,它对应的字符编码有:UTF-8、UTF-16、UTF-32）

### ASCII 码

7 个 bits 就可以完全表示 ASCII 码，其中包括 95 个可打印字符，33 个不可打印字符（包括控制字符）：

::: center
33 + 95 = 128 = 2^7^
:::

::: warning 缺陷
ASCII 的局限在于只能显示 26 个基本拉丁字母、阿拉伯数字和英式标点符号，因此只能用于显示现代美国英语，对其他语言依然无能为力
:::

### ASCII 码的扩展性

随着时间的发展，ASCII 码逐渐的满足不了更多的需求了，主要表现在很多应用或者国家中的符号都无法表示，这时就对 ASCII 码进行了第一次扩充，将 7bits 增加到 8bits，就可以让 ASCII 码表示 256 个字符，于是产生了可扩展的 ASCII 码

### 字符编码集的国际化

在世界上，很多语言的体系都不一样，很多都是不以有限字符组合的语言，比如英文只用 26 个英文字母表示，而中文除了偏旁以外，每一个字都是独立的，这些字符尤以中国、韩国、日本等国家的语言最为复杂，所以字符编码集的国际化非常有必要

#### 中文编码集

+ GB2312：又叫《信息交换用汉字编码字符集——基本集》，一共收录了 7445 个字符，包括 6763 个汉字和 682 个其他符号，虽然 GB2312 算是一个比较完备的中文字符集，但是并不符合国际标准
+ GBK：又叫《汉字内码扩展规范》，向下兼容 GB2312，向上支持国际 ISO 标准，收录了 21003 个汉字，支持中日韩全部字符

不管中文编码如何完善，只是一个本地化的编码，跨国使用都会出现乱码现象

### Unicode

又被称为统一码，万国码，单一码，从字面意思来看，Unicode 可以表示全世界所有的字符，Unicode 定义了世界通用的符号集，UTF-* 实现了编码，UTF-8 以字节为单位对 Unicode 进行编码

::: tip
在中国的 Windows 系统是默认使用 GBK 编码，编程时必须注意这个问题
:::

## 计算机的语言 - 指令

要想计算机听从指挥，就必须使用计算机的语言，早期的计算机指令是通过打孔带编写的，因为当时的计算机不能够理解数字信号，到如今计算机也只能理解所谓的机器码，比如 0 和 1 组成的指令。

从硬件角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法，乘法各种处理逻辑

从软件角度来看，CPU 就是一个执行各种计算机指令的逻辑机器，这里的计算机指令就是机器语言

但是，不同的 CPU 能听懂的语言不一样，它们各自支持的语言就是两种不同的计算机指令集，所以在电脑上写的程序，复制粘贴到手机上肯定没法运行的。但是如果复制到另一个电脑就能够运行，因为这两台电脑的 CPU 有相同的指令集

::: tip 机器语言
二进制表示形式
:::

### 从高级语言转向低级语言

对于高级语言来说，通常需要编译器翻译成汇编语言，然后通过汇编器翻译成机器语言来交给计算机执行，这是一个日常开发程序的过程

### 指令的形式

机器指令主要由两部分组成：操作码和地址码

+ 操作码指明指令要完成的操作，操作码的位数反映了机器的操作种类，比如 2^8^ 决定了操作码可以完成 256 次操作
+ 地址码用来指出操作数或操作数的地址，使 CPU 找到数据的地址进行相关运算

地址码又分为：三地址指令、二地址指令、一地址指令、零地址指令

+ 三地址指令：有三个地址码，将操作结果放入另外一个地址
+ 二地址指令：有两个地址码，将操作结果放入其中一个地址
+ 一地址指令：有一个地址码，对操作数自身进行操作并覆盖
+ 零地址指令：没有地址码，空操作，停机操作，中断返回操作等不需要操作数的操作

### 机器指令的操作类型

对于 CPU 来说，可以使用的指令很多，但大致可以分为五大类：

+ 算术类：加减乘除在 CPU 层面，都会变成一条条算术指令
+ 数据传输类：赋值变量，读写数据都是数据传输类指令完成的
+ 逻辑类：与或非
+ 条件分支类：if/else
+ 无条件跳转类：函数或者方法

不同的 CPU 有不同的指令集，也就对应着不同的汇编语言和不同的机器码

### 寻址方式

存储器即可以存放数据，又可以存放指令，其在存储单元中的编号就是地址。

#### 指令寻址

1. 顺序寻址：指令地址在内存中按顺序排列，按一条指令接一条指令的顺序进行
2. 跳跃寻址：指下条指令的地址码不是计数器给的，而是由当前指令给出，跳转到某个位置开始进行

#### 数据寻址

1. 立即寻址：指令直接获得操作数，地址字段指出的不是操作数的地址，而是操作数本身，特点是操作数立即可用，节省了访问内存的时间，但限制了操作数表示范围
2. 直接寻址：直接给出操作数在主存的地址 寻找方式简单，无需计算数据地址，但限制了操作数寻址范围
3. 间接寻址：给出的是操作数地址的地址，需要访问一次或多次主存来获取操作数，操作数寻址范围大，但速度较慢

### 指令集

标准指令集可以运行不同程序,是计算机通用性的基础，不同指令集的主要差异在于指令格式和操作数数目上

RISC 和 CISC 有以下区别：

1. 指令长度

+ 定长指令集(如MIPS):所有指令都具有固定的宽度,通常为4字节
+ 变长指令集(如x86):不同指令可能有不同的长度,从1字节到15字节不等

2. 操作数数目

+ RISC指令集(如ARM):大多只有2个源操作数和1个目标操作数
+ CISC指令集(如x86):一个指令可以有0-3个操作数不等

3. 指令结构

+ RISC指令使用固定格式,如Opcode+寄存器1+寄存器2+寄存器目标
+ CISC指令格式复杂,可能包含立即数、内存地址等不同字段

4. 操作类型

+ RISC指令集偏重简单基本运算
+ CISC指令集提供复杂的高级运算指令

5. 内存寻址方式

+ 直接寻址、寄存器间接寻址等简单寻址方式
+ 立即数偏移寻址、多级寻址等复杂寻址方式

CISC和RISC是两种主流的计算机体系结构设计理念:

CISC(Complex Instruction Set Computing):

复杂指令集计算机体系结构。

指令集复杂,一个指令可以执行多个操作。如Intel x86架构。

指令长度和格式不固定,同时支持复杂指令和简单指令。

强调功能丰富,一个指令可以完成相对复杂的任务。

RISC(Reduced Instruction Set Computing):

简化指令集计算机体系结构。

指令集简单,每个指令只执行一个基本操作。如ARM、MIPS架构。

指令长度和格式固定,只支持简单的算术逻辑单端操作。

强调高效便捷,指令简单易预测,优化指令级并行执行。

差异点总结:

CISC指令集复杂丰富,RISC指令集简化精干。

CISC重功能,RISC重效率。

CISC适合任务型 computers,RISC适合系统级应用。

CISC解码复杂,RISC解码简单。

RISC并行执行能力强,性能通常优于CISC。

所以CISC/RISC代表两种不同的计算机体系结构设计思路,但现代CPU多采用混合设计。

x86指令集:

Intel Core系列CPU(i3、i5、i7等)
Intel Pentium系列
AMD Ryzen系列CPU
Intel Celeron
ARM指令集:

Apple A系列(iPhone、iPad使用)
高通Snapdragon(Android手机常用)
联发科麒麟芯片
三星Exynos
谱豪Hisilicon(华为自研芯片)
MIPS指令集:

Loongson CPU(中国自研CPU)
日新电机Jupiter系列CPU
Broadcom视频处理芯片
天顺电子ZyLOG芯片
PowerPC指令集:

Freescale系列CPU
IBM PowerPC
-苹果早期计算机使用PowerPC
SPARC指令集:

甲骨文(Oracle)硅谷和UltraSPARC系列CPU
Fujitsu sparc64系列CPU
RISC-V指令集:

动电北极星RV32IMAC CPU
微芯系列RV64GCcpu
Mythic竞相处理器集群
Western Digital瑞云RISC-V SoC

## 管线

CPU工作过程分成多段(取指、解码、执行等),不同指令可以在不同阶段进行。

达到同时在不同阶段进行不同指令处理的目的,增强单个CPU的并行效率。

一个简单的5级流水线包括取指、解码、执行、访存、写回五个阶段。

但是会有数据依赖和控制迁移导致的流水线冲突问题。

管线技术增加单核性能

## 超标量

## 多核

在单片机上集成2个或更多完整的CPU核心。

每个核心有独立的控制单元和执行单元,但可能共享缓存和总线等资源。

让CPU在线程级实现并行执行,充分利用Instruction Level Parallelism。

多核CPU通过任务和线程的分配来提高整体吞吐量。

但也增加了结构复杂度,需要考虑NUMA等问题进行优化

多核技术通过让多个CPU核心协调工作来提高吞吐量

## 分支预测

## 协处理器

## 存储器

存储器可以简单理解为计算机用来临时保存数据和程序的部件,是CPU操作的对象。

常见的存储器类型有RAM(内存)和ROM(只读内存)。RAM是计算机运行必不可少的主要内存。

RAM的数据保存在电容中,需要持续供电才能保存存储的数据。断电则会丢失 contenyt。

RAM的核心存储单元是DRAM,按 generations 来分为DDR1、DDR2、DDR3、DDR4等版本。

RAM的主要技术参数包括:容量、时钟频率、波特率(数据传输速率)、访问时间等。

内存越大,可以存放的程序和数据就越多;时钟频率越高,数据读取速度越快。

CPU通过总线与内存进行数据交换,用逻辑地址寻址内存中的存储位置。

运行程序时,会把部分代码和数据从硬盘搬移到RAM中使用,这称为虚拟内存。

ROM在没有电源的情况下也能保持数据,一般内置BIOS固件用于系统启动。

存储器作为系统重要组成,其性能直接影响系统运行速度

## 总线

总线是计算机系统内各组件进行通信的重要路径。来让我给你介绍一下计算机总线知识:

总线可以理解为计算机系统内部联通各组件的"道路"。它负责组件之间的数据和控制信号传输。

计算机主要有三类总线:地址总线、数据总线、控制总线。

地址总线传输内存地址和I/O设备地址信息。数据总线传输数据信息。控制总线传输控制信号。

总线的带宽决定了系统传输性能。例如32位总线每次只能传输32bit的数据。

PCIe总线和SATA总线用于连接外部扩展设备。

USB和显示接口采用的也是总线结构。

与CPU连接的前端总线包括FSB总线和现在的DMI总线。

内存使用的总线包括双通道以及四通道DDR总线等。

总线传输速率越高,系统传输性能越强,例如USB3.0等。

总之,总线就像计算机系统内部“公共交通”,它的类型和速度直接影响系统各组件间的通信效率

## 参考资料

+ 程序是怎样跑起来的
+ 编码-隐匿在计算机软硬件背后的语言
+ 计算的本质：深入剖析程序和计算机
+ 计算机程序的构造和解释
+ 计算机是怎样跑起来的
+ 计算机体系结构：量化研究方法
+ 计算机系统要素：从零开始构建现代计算机
+ 计算机组成与设计：硬件软件接口
+ 深入理解计算机系统
